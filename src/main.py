import streamlit as st
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage
from options_model import LocalChat,LocalEmbedding,OnlineChat,OnlineEmbedding
from vectorstore import LocalVectorStore
import tempfile
import os

def load_api_keys():
    load_dotenv()

def initialize_ss_state():
    if "is_local" not in st.session_state:
        st.session_state.is_local = None
    if "embedding_model" not in st.session_state:
        st.session_state.embedding_model = None
    if "chat_model" not in st.session_state:
        st.session_state.chat_model = None
    if "file_list" not in st.session_state:
        st.session_state.file_list = []
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "vector_store" not in st.session_state:
        st.session_state.vector_store = None

def setup_page_config():
    st.set_page_config(
        page_title="ChatBot_PDF",  
        page_icon="üí¨",
        
    )


def setup_sidebar():
    with st.sidebar:
        st.title("Chatbot Setting")
        
        # ch·ªçn model embed
        environment = st.selectbox(label="Choosing type", 
                                options=("Online", "Local"),
                                label_visibility="collapsed")
        st.session_state.is_local = False if environment == "Online" else True
        chat_models = OnlineChat.keys() if environment == "Online" else LocalChat.keys()
        embedding_models = OnlineEmbedding.keys() if environment == "Online" else LocalEmbedding.keys()


        # Ch·ªçn m√¥ h√¨nh chat v√† m√¥ h√¨nh embedding
        selected_chat_model = st.selectbox("Choose Chat Model", options=chat_models)
        st.session_state.chat_model = selected_chat_model
        selected_embedding_model = st.selectbox("Choose Embedding Model", options=embedding_models)
        st.session_state.embedding_model = selected_embedding_model

        # x√≥a l·ªãch s·ª≠ chat
        if st.button(label="Clear history"):
            st.session_state.chat_history = []
            print("Delete history")
        uploaded_files=st.file_uploader(label="Upload Pdf documents",
                         type=["pdf"],
                         accept_multiple_files=True
                         )
        st.session_state.file_list = uploaded_files
        if st.button(label="Upload"):
            handle_files_input(uploaded_files)

def handle_files_input(uploaded_files):
    if len(uploaded_files) == 0:
        st.warning("B·∫°n c·∫ßn t·∫£i √≠t nh·∫•t m·ªôt file PDF tr∆∞·ªõc khi chat.")
        st.stop()  # L·ªánh n√†y s·∫Ω d·ª´ng c√°c ph·∫ßn code b√™n d∆∞·ªõi, ·∫©n lu√¥n giao di·ªán chat

    temp_paths = []  # Danh s√°ch ƒë∆∞·ªùng d·∫´n t·∫°m th·ªùi c·ªßa c√°c file
    try:
        
        for uploaded_file in uploaded_files:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.read())  # Ghi d·ªØ li·ªáu v√†o file
                temp_paths.append(tmp_file.name)  # L∆∞u ƒë∆∞·ªùng d·∫´n file t·∫°m v√†o danh s√°ch

        with st.spinner("Vui l√≤ng ch·ªù trong gi√¢y l√°t"):
            vector_store = LocalVectorStore(st.session_state.is_local, st.session_state.embedding_model)
            vector_store.set_vectorstore(input_files=temp_paths)
            st.session_state.vector_store = vector_store

    except Exception as e:
                st.error(f"‚ùå l·ªói {str(e)}")
    finally:
            # X√≥a t·ª´ng file t·∫°m
        for path in temp_paths:
            try:
                os.remove(path)
            except Exception as e:
                st.warning(f"Kh√¥ng th·ªÉ x√≥a file t·∫°m {path}: {e}")
        


def display_chat_history():
    st.title("Asisstant ChatBot")
    # kh·ªüi t·∫°o chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # hi·ªÉn th·ªã tin nh·∫Øn tr√≤ chuy·ªán t·ª´ l·ªãch s·ª≠ khi ch·∫°y l·∫°i ·ª©ng d·ª•ng
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])


def handle_user_input(llm_with_tools):

    # ƒë·∫ßu v√†o ng∆∞·ªùi d√πng
    if prompt:=st.chat_input(placeholder="Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n ·ªü ƒë√¢y?"):
        # th√™m tin nh·∫Øn ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ chat
        st.session_state.messages.append({"role": "user", "content": prompt})
        # hi·ªÉn th·ªã tin nh·∫Øn ng∆∞·ªùi d√πng trong chat message container
        with st.chat_message("user"):
            st.write(prompt)
        
        # hi·ªÉn th·ªã ph·∫£n h·ªìi c·ªßa ai trong chat message container
        with st.chat_message("assistant"):
            # l·∫•y l·ªãch s·ª≠ chat l∆∞u trong session_state
            chat_history = []
            for message in st.session_state.messages[:-1]:
                chat_history.append({"role": message["role"], "content": message["content"]})
            # l·∫•y ph·∫£n h·ªìi t·ª´ chain
            # response = chain.invoke({
            #     "input": prompt,
            #     "chat_history": chat_history    
            #     }
            # )
            reponse = llm_with_tools.invoke([HumanMessage(content=prompt)])
            print("chat history: \n", chat_history)
            st.write(reponse)
        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": output})
        


def main():

    initialize_ss_state()
    load_api_keys()
    setup_page_config()
    setup_sidebar()
    # display_chat_history()
    # handle_user_input(agent_rag)
    print("#######################")


if __name__ == "__main__":
    main()

