import streamlit as st
from database_vector import create_ChromaDB
from crawler import pdf_to_text
from chain_retrieval import create_chain
from dotenv import load_dotenv

def load_api_keys():

    load_dotenv()

def setup_page_config():
    st.set_page_config(
        page_title="ChatBot_PDF",  
        page_icon="üí¨",
        
    )

def handle_file(embedd_model):
    st.header("T·∫£i t·ªáp PDF ")
    pdf_file = st.file_uploader(label="Upload pdf here", type= ["pdf"])

    if pdf_file is not None:
        # with st.spinner("Vui l√≤ng ch·ªù trong gi√¢y l√°t"):
        #     try:

        #         db = create_ChromaDB(pdf_file=pdf_file, embed_model=embedd_model)
        #         st.success("T·∫°o vectorDB th√†nh c√¥ng.")
        #     except Exception as e:
        #         st.error(f" l·ªói {str(e)}")
        pass
        
        # return chunks
    else:
        st.warning("B·∫°n c·∫ßn t·∫£i √≠t nh·∫•t m·ªôt file PDF tr∆∞·ªõc khi chat.")
        st.stop()  # L·ªánh n√†y s·∫Ω d·ª´ng c√°c ph·∫ßn code b√™n d∆∞·ªõi, ·∫©n lu√¥n giao di·ªán chat
    


def setup_sidebar():
    with st.sidebar:
        st.title("Chatbot Setting")
    
        # ch·ªçn model chat
        chat_model = st.sidebar.selectbox(label="L·ª±a ch·ªçn model chat", options=["llama3.1", "gpt-4o-mini"])
        if chat_model == "llama3.1":
            # chain = create_chain(chat_model)
            print("Model chat: ",chat_model)
        else: # gpt4o-mini
            # chain = create_chain(chat_model)
            print("model chat: ", chat_model)
        
        # ch·ªçn model embed
        embedd_model = st.sidebar.selectbox(label="L·ª±a ch·ªçn model embedding", 
                                            options=["nomic-embed-text", "text-embedding-3-large"])

        if embedd_model == "llama3.1":
            # chain = create_chain(embedd_model)
            print("Model chat: ",embedd_model)
        else: # text-embedding-3-large
            # chain = create_chain(embedd_model)
            print("model embedding: ", embedd_model)
        # x√≥a l·ªãch s·ª≠ chat
        if st.button(label="Clear history"):
            st.session_state.message = []
            print("Delete history")

    return embedd_model


def display_chat_history():
    st.title("Asisstant ChatBot")
    # kh·ªüi t·∫°o chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # hi·ªÉn th·ªã tin nh·∫Øn tr√≤ chuy·ªán t·ª´ l·ªãch s·ª≠ khi ch·∫°y l·∫°i ·ª©ng d·ª•ng
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])


def handle_user_input():

    # ƒë·∫ßu v√†o ng∆∞·ªùi d√πng
    if prompt:=st.chat_input(placeholder="Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n ·ªü ƒë√¢y?"):
        # th√™m tin nh·∫Øn ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ chat
        st.session_state.messages.append({"role": "user", "content": prompt})
        # hi·ªÉn th·ªã tin nh·∫Øn ng∆∞·ªùi d√πng trong chat message container
        with st.chat_message("user"):
            st.write(prompt)
        
        # hi·ªÉn th·ªã ph·∫£n h·ªìi c·ªßa ai trong chat message container
        with st.chat_message("assistant"):
            # l·∫•y l·ªãch s·ª≠ chat l∆∞u trong session_state
            chat_history = []
            for message in st.session_state.messages[:-1]:
                chat_history.append({"role": message["role"], "content": message["content"]})
            #l·∫•y ph·∫£n h·ªìi t·ª´ chain
            # response = chain.invoke({
            #     "input": prompt,
            #     "chat_history": chat_history    
            #     }
            # )
            output = "AI, " + prompt
            print("chat history: \n", chat_history)
        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": output})
        


def main():

    load_api_keys()
    setup_page_config()
    embedd_model = setup_sidebar()
    handle_file(embedd_model)
    display_chat_history()
    handle_user_input()


if __name__ == "__main__":
    main()

